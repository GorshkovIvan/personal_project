{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from louvain_ascendency.ipynb\n",
      "importing Jupyter notebook from mixer_ascendency.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import import_ipynb\n",
    "from louvain_ascendency import*\n",
    "from mixer_ascendency import*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class graph_analyser():\n",
    "    \n",
    "    def __init__(self, conn, graph_name):\n",
    "        self.conn = conn\n",
    "        self.addresses_in_large_communities = {} # communitity id => addresses in community\n",
    "        self.large_communities = [] # stores ids of large communities\n",
    "        self.subgraphs = {} # adjacency matrices of subgraphs of all communities \n",
    "        self.metrics_by_community = {} # dict of dicts of graph state metrics by community\n",
    "        self.metric_names = [\"Average Mutual Information\", \"Development capacity\", \"Ascendency\", \"Redundancy\"]\n",
    "        self.address_to_node_by_subgraph = {} # dicts of address to node in each subgraph\n",
    "        self.graph_name = graph_name \n",
    "        self.remove_full_graph_from_neo4j()\n",
    "        self.create_token_graph_neo4j()\n",
    "        self.centrality_scores_by_community = {}\n",
    "        self.get_full_graph_adj_matrix()\n",
    "        \n",
    "    def create_token_graph_neo4j(self):\n",
    "        name = self.graph_name \n",
    "        print(name)\n",
    "        \n",
    "        query_string = '''CALL gds.graph.create(\n",
    "                            '%s',\n",
    "                            'Address',\n",
    "                            {\n",
    "                                TRANSFER_%s: {\n",
    "                                    type: 'TRANSFERED_%s',\n",
    "                                    orientation: 'NATURAL',\n",
    "                                    properties: 'value'\n",
    "\n",
    "                                }\n",
    "                            }\n",
    "                        )''' %(name, name, name)\n",
    "        self.conn.query(query_string)\n",
    "       \n",
    "\n",
    "        \n",
    "    def get_full_graph_adj_matrix(self):\n",
    "        query_string = '''MATCH (n1:Address)-[r:TRANSFERED_%s]->(n2:Address)\n",
    "                          RETURN n1.id AS From, n2.id AS To, r.value AS value''' %(self.graph_name)\n",
    "        \n",
    "        full_graph = pd.DataFrame([dict(_) for _ in self.conn.query(query_string)])\n",
    "        self.full_graph_adj_matrix = self.pandas_edge_list_to_adj_matrix(full_graph, \"full\")\n",
    "        \n",
    "    def check_if_graph_exists_neo4j(self):\n",
    "        query_string = \"CALL gds.graph.exists('%s')\"%(self.graph_name)\n",
    "        exists = self.conn.query(query_string)\n",
    "        response_df = pd.DataFrame([dict(_) for _ in exists])\n",
    "        \n",
    "        return response_df['exists'][0]\n",
    "    \n",
    "    def run_louvain(self, threshold):\n",
    "        \n",
    "        query_string = '''CALL gds.louvain.write(\n",
    "                        '%s',\n",
    "                        {\n",
    "                            tolerance: %d,\n",
    "                            writeProperty: 'communityId',\n",
    "                            relationshipWeightProperty: 'value'\n",
    "                        }\n",
    "                    )'''%(self.graph_name, threshold)\n",
    "        self.conn.query(query_string)\n",
    "        \n",
    "    def create_subgraph_from_community_id(self, community_id):\n",
    "        query_string = '''CALL gds.graph.create.cypher(\n",
    "                        'community-%d',\n",
    "                        'MATCH (n) WHERE n.communityId = %d RETURN id(n) AS id',\n",
    "                        'MATCH (n)-[r:TRANSFERED_%s]->(m) WHERE n.communityId = %d AND m.communityId = %d RETURN id(n) AS source, id(m) AS target, r.value AS value'\n",
    "                    ) ''' %(community_id, community_id, self.graph_name, community_id, community_id)\n",
    "        self.conn.query(query_string)\n",
    "        \n",
    "    def calculate_subgraph_centrality(self, community_id):\n",
    "        query_string = '''CALL gds.degree.stream('community-%d')\n",
    "                            YIELD nodeId, score\n",
    "                            RETURN gds.util.asNode(nodeId).id AS address, score AS degreeCentrality\n",
    "                            ORDER BY degreeCentrality DESC''' %(community_id)\n",
    "        centrality_scores = pd.DataFrame([dict(_) for _ in self.conn.query(query_string)])\n",
    "        \n",
    "        return centrality_scores\n",
    "    \n",
    "    def get_node_community_id(self, address):\n",
    "        \n",
    "        query_string = '''MATCH (n) WHERE n.id = \"%s\" RETURN n.communityId as community''' %(address)\n",
    "        community_id = pd.DataFrame([dict(_) for _ in self.conn.query(query_string)])\n",
    "        return community_id[\"community\"]\n",
    "    \n",
    "    def remove_all_community_ids(self):\n",
    "        \n",
    "        query_string = '''MATCH (n:Address)\n",
    "                            REMOVE n.communityId\n",
    "                            RETURN n '''\n",
    "        self.conn.query(query_string)\n",
    "    \n",
    "    def calculate_centrality_score_for_every_community(self):\n",
    "        \n",
    "        for community_id in self.large_communities:\n",
    "            self.create_subgraph_from_community_id(community_id)\n",
    "            self.centrality_scores_by_community[community_id] = self.calculate_subgraph_centrality(community_id)\n",
    "            self.remove_graph_from_neo4j(community_id)\n",
    "            \n",
    "    def calculate_degree_centrality_for_all_nodes(self):\n",
    "        \n",
    "            \n",
    "        query_string = '''CALL gds.degree.stream('%s')\n",
    "                            YIELD nodeId, score\n",
    "                            RETURN gds.util.asNode(nodeId).id AS address, score AS degreeCentrality\n",
    "                            ORDER BY degreeCentrality DESC''' %(self.graph_name)\n",
    "        \n",
    "        self.centrality_score_by_node = pd.DataFrame([dict(_) for _ in self.conn.query(query_string)])\n",
    "        \n",
    "    def calculate_pageRank_centrality_for_all_nodes(self):\n",
    "        \n",
    "        query_string = '''CALL gds.pageRank.stream('%s')\n",
    "                            YIELD nodeId, score\n",
    "                            RETURN gds.util.asNode(nodeId).id AS address, score AS degreeCentrality\n",
    "                            ORDER BY degreeCentrality DESC''' %(self.graph_name)\n",
    "        \n",
    "        self.pageRank_centrality_score_by_node = pd.DataFrame([dict(_) for _ in self.conn.query(query_string)])\n",
    "        \n",
    "    def remove_graph_from_neo4j(self, community_id):\n",
    "        \n",
    "        query_string = '''CALL gds.graph.drop('community-%d')''' %(community_id)\n",
    "        self.conn.query(query_string)\n",
    "        \n",
    "    def remove_full_graph_from_neo4j(self):\n",
    "        query_string = '''CALL gds.graph.drop('%s')''' %(self.graph_name)\n",
    "        self.conn.query(query_string)\n",
    "        \n",
    "    def find_large_communities(self, threshold):\n",
    "        query_string = '''MATCH (n:Address)\n",
    "                        WHERE EXISTS(n.communityId)\n",
    "                        RETURN n.communityId AS communityId, COUNT(*) AS size\n",
    "                        ORDER BY size DESC'''\n",
    "\n",
    "        size_of_communities = pd.DataFrame([dict(_) for _ in self.conn.query(query_string)])\n",
    "        \n",
    "        for index, row in size_of_communities.iterrows():\n",
    "            if(row['size'] > threshold):\n",
    "                self.large_communities.append(row['communityId'])\n",
    "        return self.large_communities\n",
    "    \n",
    "    def get_all_community_addresses(self, community_id):\n",
    "        query_string = '''MATCH (n)\n",
    "                          WHERE n.communityId = ''' \n",
    "        query_string = query_string + str(community_id) \n",
    "        query_string += '''RETURN n.id as id'''\n",
    "\n",
    "        addresses_in_community = pd.DataFrame([dict(_) for _ in self.conn.query(query_string)])\n",
    "        return addresses_in_community['id'].tolist()\n",
    "    \n",
    "    def get_all_addresses_from_large_communities(self):\n",
    "        \n",
    "        for community in self.large_communities:\n",
    "            self.addresses_in_large_communities[community] = self.get_all_community_addresses(community)\n",
    "        \n",
    "    def get_node_degree(self, node_address):\n",
    "    \n",
    "        query_string = '''MATCH (n:Address {id: \\\"'''\n",
    "        query_string += str(node_address)\n",
    "        query_string +=  '\"})'\n",
    "        query_string += '''RETURN apoc.node.degree(n) AS degree '''\n",
    "\n",
    "        degree = pd.DataFrame([dict(_) for _ in self.conn.query(query_string)])\n",
    "\n",
    "        return degree['degree'][0]\n",
    "    \n",
    "    def get_address_with_highest_degree(self, community_id):\n",
    "        a = \"0x\"\n",
    "        highest_degree = 0\n",
    "        for address in self.large_communities[community_id]:\n",
    "            node_degree = self.get_node_degree(address, self.conn)\n",
    "            if node_degree > highest_degree:\n",
    "                highest_degree = node_degree\n",
    "                a = address\n",
    "\n",
    "        return a, highest_degree\n",
    "    \n",
    "    def get_subgraph_by_community_id(self, community_id):\n",
    "        \n",
    "        query_string = '''MATCH (a1:Address)-[r:TRANSFERED_%s]->(a2:Address)''' %(self.graph_name)\n",
    "        query_string += '''WHERE a1.communityId = ''' + str(community_id) \n",
    "        query_string +=  '''AND a2.communityId =''' + str(community_id)\n",
    "        query_string += '''RETURN a1.id as From, a2.id as To, r.value as value'''\n",
    "\n",
    "        subgraph = pd.DataFrame([dict(_) for _ in self.conn.query(query_string)])\n",
    "        \n",
    "        return subgraph\n",
    "    '''\n",
    "    def convert_subgraph_into_adj_matrix(self, subgraph):\n",
    "        \n",
    "        Graphtype = nx.DiGraph()\n",
    "        G=nx.from_pandas_edgelist(subgraph, 'From', 'To', ['value'], create_using=Graphtype)\n",
    "        g_numpy = nx.to_numpy_array(G)\n",
    "        \n",
    "        return g_numpy \n",
    "    '''\n",
    "    def calculate_metrics(self, subgraph_adj_matrix):\n",
    "       \n",
    "        ami = measure_average_mutual_information(subgraph_adj_matrix)\n",
    "        dc = measure_development_capacity(subgraph_adj_matrix)\n",
    "        a = measure_ascendency(subgraph_adj_matrix)\n",
    "        r = measure_redundancy(subgraph_adj_matrix)\n",
    "        \n",
    "        return ami, dc, a, r\n",
    "    \n",
    "    def find_all_subgraphs(self):\n",
    "        \n",
    "        for community_id in self.large_communities:\n",
    "            graph_df = self.get_subgraph_by_community_id(community_id)\n",
    "            self.subgraphs[community_id] = self.pandas_edge_list_to_adj_matrix(graph_df, community_id)\n",
    "        \n",
    "        \n",
    "    def calculate_metrics_for_all_subgraphs(self):\n",
    "        \n",
    "        for community_id in self.subgraphs:\n",
    "            self.metrics_by_community[community_id] ={}\n",
    "            metrics = self.calculate_metrics(self.subgraphs[community_id])\n",
    "            for count, metric in enumerate(metrics):\n",
    "                self.metrics_by_community[community_id][self.metric_names[count]] = metric\n",
    "    \n",
    "    def pandas_edge_list_to_adj_matrix(self, graph_df, community_id):\n",
    "        \n",
    "        address_to_node ={}\n",
    "        count = 0\n",
    "        for index, row in graph_df.iterrows():\n",
    "            address = row[\"From\"]\n",
    "            if address not in address_to_node:\n",
    "                address_to_node[address] = count \n",
    "                count += 1\n",
    "            address = row[\"To\"]\n",
    "            if address not in address_to_node:\n",
    "                address_to_node[address] = count \n",
    "                count += 1\n",
    "        size = len(address_to_node.keys())\n",
    "        \n",
    "        adj_matrix = np.zeros((size, size))\n",
    "        self.address_to_node_by_subgraph[community_id] = address_to_node\n",
    "        \n",
    "        for index, row in graph_df.iterrows():\n",
    "            adj_matrix[address_to_node[row[\"From\"]]][address_to_node[row[\"To\"]]] = row[\"value\"]\n",
    "        \n",
    "       \n",
    "        return adj_matrix\n",
    "    \n",
    "    def perform_analysis(self, louvain_threshold, min_community_size):\n",
    "\n",
    "        self.remove_all_community_ids()\n",
    "        self.run_louvain(louvain_threshold)\n",
    "        self.find_large_communities(min_community_size)\n",
    "        self.get_all_addresses_from_large_communities()\n",
    "        self.find_all_subgraphs()\n",
    "        self.calculate_centrality_score_for_every_community()\n",
    "        self.calculate_metrics_for_all_subgraphs()\n",
    "        self.calculate_degree_centrality_for_all_nodes()\n",
    "        \n",
    "    def print_metrics_by_community(self):\n",
    "        \n",
    "        metrics_by_community = self.metrics_by_community\n",
    "        metric_names = self.metric_names\n",
    "\n",
    "        ami = np.array([])\n",
    "        dc = np.array([])\n",
    "        a = np.array([])\n",
    "        r = np.array([])\n",
    "        community_sizes = np.array([])\n",
    "        number_of_edges = np.array([])\n",
    "\n",
    "        for key in metrics_by_community:\n",
    "            community_sizes = np.append(community_sizes, len(self.addresses_in_large_communities[key]))\n",
    "            number_of_edges = np.append(number_of_edges, np.count_nonzero(self.subgraphs[key]))\n",
    "            ami = np.append(ami, metrics_by_community[key][metric_names[0]])\n",
    "            dc = np.append(dc, metrics_by_community[key][metric_names[1]])\n",
    "            a = np.append(a, metrics_by_community[key][metric_names[2]])\n",
    "            r = np.append(r, metrics_by_community[key][metric_names[3]])\n",
    "\n",
    "        all_metrics = [ami, dc, a, r]\n",
    "\n",
    "        for count, metric in enumerate(all_metrics):\n",
    "            print(\"Mean of \", metric_names[count], \" is \", np.average(metric))\n",
    "            print(\"Standard Deviation of \", metric_names[count], \" is \", np.std(metric))\n",
    "            print(\"Max of \", metric_names[count], \" is \", np.max(metric))\n",
    "            print(\"Min of \", metric_names[count], \" is \", np.min(metric))\n",
    "            print(\" \")\n",
    "\n",
    "    def find_shortest_path(self, node1_id, node2_id):\n",
    "        query_string = \"\"\"MATCH (a1:Address { id: \"%s\" }),(a2:Address { id: \"%s\" }), path = shortestPath((a1)-[*..15]->(a2))\n",
    "                            RETURN path\"\"\" %(node1_id, node2_id)\n",
    "        \n",
    "        path = self.conn.query(query_string)\n",
    "        node_ids = []\n",
    "\n",
    "        for record in path:\n",
    "            for node in record[\"path\"].nodes:\n",
    "                nodeid = node.get('id')\n",
    "                node_ids.append(nodeid)\n",
    "\n",
    "\n",
    "        return node_ids\n",
    "    \n",
    "    \n",
    "    def find_all_shortest_paths(self, node1_id, node2_id):\n",
    "        query_string = \"\"\"MATCH (a1:Address { id: \"%s\" }),(a2:Address { id: \"%s\" }), path = allShortestPaths((a1)-[*..15]->(a2))\n",
    "                            RETURN path\"\"\" %(node1_id, node2_id)\n",
    "        \n",
    "        paths = self.conn.query(query_string)\n",
    "        node_ids = []\n",
    "\n",
    "        for count, record in enumerate(paths):\n",
    "            for node in record[\"path\"].nodes:\n",
    "         \n",
    "                nodeid = node.get('id')\n",
    "                node_ids.append(nodeid)\n",
    "\n",
    "\n",
    "        return node_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
